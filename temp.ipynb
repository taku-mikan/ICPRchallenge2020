{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"{0:06d}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "annotations_sort = pd.read_csv(\"annotations_sort.csv\")\n",
    "print(\"##### filling_type kind #####\")\n",
    "print(annotations_sort[\"filling_type\"].value_counts())\n",
    "annotations_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pouring_or_shaking = np.load(\"./data_temp/audio/pouring_or_shaking.npy\").tolist()\n",
    "print(len(pouring_or_shaking))\n",
    "# print(\"pouring_or_shaking : \", pouring_or_shaking)\n",
    "\n",
    "# filling_type = np.load(\"./data/audio/filling_type.npy\").tolist()\n",
    "# print(len(filling_type))\n",
    "# print(\"filling_type : \", filling_type)\n",
    "\n",
    "# folder_count = np.load(\"./data/audio/folder_count.npy\").tolist()\n",
    "# print(\"folder_count : \", folder_count)\n",
    "\n",
    "# folder_count_detail =  np.load(\"./data/audio/folder_count_detail.npy\", allow_pickle=True).tolist()\n",
    "# print(len(folder_count_detail))\n",
    "# print(\"folder_count_detail : \", folder_count_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mydataset.pyの内容\n",
    "\n",
    "np.set_printoptions(threshold=100)\n",
    " \n",
    "pouring_or_shaking = np.load(\"./data_temp/audio/pouring_or_shaking.npy\")\n",
    "# print(len(pouring_or_shaking))\n",
    "# print(\"pouring_or_shaking : \", pouring_or_shaking)\n",
    "\n",
    "filling_type = np.load(\"./data_temp/audio/filling_type.npy\")\n",
    "# print(len(filling_type))\n",
    "# print(\"filling_type : \", filling_type)\n",
    "\n",
    "folder_count = np.load(\"./data_temp/audio/folder_count.npy\").tolist()\n",
    "print(\"folder_count : \", folder_count)\n",
    "\n",
    "# folder_count_detail =  np.load(\"./data/audio/folder_count_detail.npy\", allow_pickle=True).tolist()\n",
    "# print(len(folder_count_detail))\n",
    "# print(\"folder_count_detail : \", folder_count_detail)\n",
    "\n",
    "label = filling_type * pouring_or_shaking\n",
    "print(type(label))\n",
    "print(label.shape)\n",
    "print(len(label))\n",
    "print(\"label : \", label)\n",
    "print(np.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(range(10, 20)):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "a = list(range(0, 21))\n",
    "train_num = 15\n",
    "val_num = 5\n",
    "print(a)\n",
    "b = random.sample(a, train_num)\n",
    "c = random.sample(a, val_num)\n",
    "print(\"b : \", b)\n",
    "print(\"c : \", c)\n",
    "print(\"a == b+c ?? : \", a==sorted(b+c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6134 + 4534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# データの分割の実験\n",
    "folder_count = [6134, 4534, 4386, 3994, 4342, 5382, 1100, 1001, 923]\n",
    "# 0~6133 -> 6134 ~ 10667 -> ...\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "total_num = 0\n",
    "for i, num in enumerate(folder_count):\n",
    "    fol_indices = list(range(total_num, total_num+num))\n",
    "    fol_indices = random.sample(fol_indices, num)\n",
    "\n",
    "    # train : validation = 80 : 20\n",
    "    train_size = int(num * 0.8)\n",
    "\n",
    "    train_indices += fol_indices[0:train_size]\n",
    "    val_indices += fol_indices[train_size:]\n",
    "\n",
    "    print(\"total_num : \", total_num)\n",
    "    print(\"all_size : \", len(train_indices)+len(val_indices))\n",
    "    print(\"*******************************\")\n",
    "    \n",
    "    total_num += num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train : \",len(train_indices))\n",
    "print(\"validation : \", len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(31796 * 0.8)\n",
    "# 共通する要素がないことの確認\n",
    "dob = set(train_indices) & set(val_indices)\n",
    "print(\"重複 : \", len(dob))\n",
    "# 数が正しいかの確認\n",
    "print(\"全データ数 : \", len(train_indices)+len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfccを読み込んでみる\n",
    "# plt.subplot2gridはこれ↓\n",
    "# https://stats.biopapyrus.jp/python/subplot2grid.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa.display\n",
    "import scipy.io.wavfile\n",
    "\n",
    "for i in range(0, 9):\n",
    "    mfcc = np.load(\"./data/audio/mfcc/00000{}.npy\".format(i+1))\n",
    "    # print(\"type : \", type(mfcc))\n",
    "    # print(\"shape : \", mfcc.shape)\n",
    "\n",
    "    mfcc_ch1 = mfcc[:, :, 0]\n",
    "    # print(mfcc_ch1.shape)\n",
    "    plt.subplot2grid((3, 3), (i//3, i%3))\n",
    "    # plt.title(\"log-Mel spectgrum (ch1) of 00000{}.npy\".format(i+1))\n",
    "    plt.imshow(mfcc_ch1)\n",
    "    # plt.tick_params()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUdioProcessing.pyのmainの中のコードの実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessing():\n",
    "    # mfccに関するわかりやすそうな記事\n",
    "    # https://aidiary.hatenablog.com/entry/20120225/1330179868\n",
    "    # https://qiita.com/tmtakashi_dist/items/eecb705ea48260db0b62\n",
    "    def __init__(self,sample_rate,signal,frame_length_t=0.025,frame_stride_t=0.01,nfilt =64):\n",
    "        \n",
    "        self.sample_rate=sample_rate\n",
    "        self.signal = signal\n",
    "        self.frame_length_t=frame_length_t\n",
    "        self.frame_stride_t=frame_stride_t\n",
    "        self.signal_length_t=float(signal.shape[0]/sample_rate)\n",
    "        self.frame_length=int(round(frame_length_t * sample_rate)) #number of samples\n",
    "        self.frame_step=int(round(frame_stride_t * sample_rate))\n",
    "        self.signal_length = signal.shape[0]\n",
    "        self.nfilt=nfilt\n",
    "        self.num_frames = int(np.ceil(float(np.abs(self.signal_length - self.frame_length)) / self.frame_step))\n",
    "        self.pad_signal_length=self.num_frames * self.frame_step + self.frame_length\n",
    "        self.NFFT=512 # fftのサンプル数(記事中のN)\n",
    "        \n",
    "    def calc_MFCC(self):\n",
    "        # mfccへの変換手順\n",
    "        # (1) 波形を適当な長さで分割し、窓関数をかけ、fftを行う\n",
    "        pre_emphasis=0.97\n",
    "        emphasized_signal=np.concatenate([self.signal[0,:].reshape([1,-1]),  self.signal[1:,:] - pre_emphasis * self.signal[:-1,:]], 0)\n",
    "        z = np.zeros([self.pad_signal_length - self.signal_length,8])\n",
    "        pad_signal = np.concatenate([emphasized_signal, z], 0)\n",
    "        indices = np.tile(np.arange(0, self.frame_length), (self.num_frames, 1)) + np.tile(np.arange(0, self.num_frames * self.frame_step, self.frame_step), (self.frame_length, 1)).T\n",
    "        frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "\n",
    "        # (2) 窓処理を行なって、振幅スペクトルを求める\n",
    "        # ハミング窓をかける\n",
    "        frames=frames*np.hamming(self.frame_length).reshape(1,-1,1)\n",
    "        frames=frames.transpose(0,2,1)\n",
    "        mag_frames = np.absolute(np.fft.rfft(frames,self.NFFT)) # spec(記事中の)\n",
    "        pow_frames = ((1.0 / self.NFFT) * ((mag_frames) ** 2)) # fscale(記事中の)\n",
    "\n",
    "        # (3) メルフィルタバンクをかける\n",
    "        filter_banks = np.dot(pow_frames, self.cal_fbank().T)\n",
    "        # np.where : https://numpy.org/doc/stable/reference/generated/numpy.where.html\n",
    "        filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
    "        filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "        # np.transpose : https://numpy.org/doc/stable/reference/generated/numpy.transpose.html\n",
    "        # -->　配列の軸の順番を入れ替える\n",
    "        filter_banks =filter_banks.transpose(0,2,1)\n",
    "\n",
    "        # (3) 離散コサイン変換を行う --> やってない : 深層学習と合わないとかなんだとか\n",
    "        \n",
    "        return filter_banks\n",
    "           \n",
    "    def cal_fbank(self):\n",
    "        # おそらくメルフィルタバンクなるものを作る関数\n",
    "        low_freq_mel = 0\n",
    "        high_freq_mel = (2595 * np.log10(1 + (self.sample_rate / 2) / 700))  \n",
    "        mel_points = np.linspace(low_freq_mel, high_freq_mel, self.nfilt + 2)  \n",
    "        hz_points = (700 * (10**(mel_points / 2595) - 1)) \n",
    "        bin = np.floor((self.NFFT + 1) * hz_points / self.sample_rate)\n",
    "        fbank = np.zeros((self.nfilt, int(np.floor(self.NFFT / 2 + 1))))\n",
    "        for m in range(1, self.nfilt + 1):\n",
    "            f_m_minus = int(bin[m - 1])   # left\n",
    "            f_m = int(bin[m])             # center\n",
    "            f_m_plus = int(bin[m + 1])    # right\n",
    "\n",
    "            for k in range(f_m_minus, f_m):\n",
    "                fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "            for k in range(f_m, f_m_plus):\n",
    "                fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "        return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./data_temp/1//audio/s0_fi0_fu0_b0_l0_audio.wav\"\n",
    "# audio_path = \"./data/1//audio/s0_fi0_fu0_b0_l1_audio.wav\"\n",
    "save_size = 64\n",
    "sample_rate, signal = scipy.io.wavfile.read(audio_path)\n",
    "\n",
    "print(\"save_size : \", save_size)\n",
    "print(\"sample_rate : \", sample_rate)\n",
    "print(\"signal=type : \", type(signal))\n",
    "print(\"signal-shape ; \", signal.shape)\n",
    "        \n",
    "ap = AudioProcessing(sample_rate,signal,nfilt=save_size)\n",
    "mfcc = ap.calc_MFCC()\n",
    "print(\"mfcc-type : \", type(mfcc))\n",
    "print(\"mfcc-shape : \", mfcc.shape)\n",
    "mfcc_length=mfcc.shape[0]\n",
    "print(\"mfcc_length : \", mfcc_length)\n",
    "\n",
    "\n",
    "ratio_step = 0.25\n",
    "\n",
    "f_step=int(mfcc.shape[1]*ratio_step)\n",
    "print(\"mfcc.shape[1] : \", mfcc.shape[1])\n",
    "print(\"f_step : \", f_step)\n",
    "f_length=mfcc.shape[1]\n",
    "print(\"f_length : \", f_length)\n",
    "\n",
    "\n",
    "save_mfcc_num=int(np.ceil(float(np.abs(mfcc_length - save_size)) / f_step))\n",
    "print(\"save_mfcc_num : \", save_mfcc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "count = 0\n",
    "df = pd.read_csv(\"annotations.csv\", header=0)\n",
    "fileidx = 0\n",
    "file_name = df.iat[fileidx, 2]\n",
    "folder_num = df.iat[fileidx, 0] # container_id\n",
    "start_time =  df.iat[fileidx, 9]\n",
    "end_time = df.iat[fileidx, 10]\n",
    "filling_type = df.iat[fileidx, 4]\n",
    "\n",
    "# for i in range(save_mfcc_num):\n",
    "#     count += 1\n",
    "#     tmp_mfcc = mfcc[i*f_step:save_size+i*f_step,: ,:] # (64, 64, 8)\n",
    "\n",
    "#     if start_time == -1:\n",
    "#         pouring_or_shaking_list.append(0)\n",
    "#     elif start_time/ap.signal_length_t*mfcc_length<i*f_step+f_length*0.75 and end_time/ap.signal_length_t*mfcc_length>i*f_step+f_length*0.25:\n",
    "#         pouring_or_shaking_list.append(1) \n",
    "#     else:\n",
    "#         pouring_or_shaking_list.append(0)\n",
    "    \n",
    "#     filling_type_list.append(filling_type)\n",
    "#     file_idx_list.append(fileidx)\n",
    "#     folder_count[folder_num-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トリミングの実装練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "audio_path = \"./data_temp/1//audio/s0_fi0_fu0_b0_l0_audio.wav\"\n",
    "# audio_path = \"./data/1//audio/s0_fi0_fu0_b0_l1_audio.wav\"\n",
    "save_size = 64\n",
    "threshold = 20\n",
    "sample_rate, signal = scipy.io.wavfile.read(audio_path)\n",
    "\n",
    "print(\"save_size : \", save_size)\n",
    "print(\"sample_rate : \", sample_rate)\n",
    "print(\"signal-type : \", type(signal))\n",
    "print(\"signal-dtype ; \", signal.dtype)\n",
    "print(\"signal-shape ; \", signal.shape)\n",
    "\n",
    "signal_float = signal.astype(\"float32\")\n",
    "print(\"signal_float.dtype : \", signal_float.dtype)\n",
    "\n",
    "print(\"signal_float : \", signal_float)\n",
    "\n",
    "print(\"##### traiming #####\")\n",
    "signal, _ = librosa.effects.trim(signal_float, top_db=threshold)\n",
    "print(\"signal_type : \", type(signal))\n",
    "print(\"signal_shape : \", signal.shape)\n",
    "print(\"signal : \", signal)\n",
    "# int へ戻す\n",
    "print(\"##### return int #####\")\n",
    "signal = signal.astype(\"int16\")\n",
    "# # 正規化\n",
    "# print(\"##### normalization #####\")\n",
    "# signal /= np.abs(signal).max()\n",
    "# signal = signal.astype(\"int16\")\n",
    "print(\"signal.dtype : \", signal.dtype)\n",
    "print(\"signal.shape\", signal.shape)\n",
    "print(\"signal : \", signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音声データのdBを何個か表示してみる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d750b1d6ed462e38525a0d8227ea288a7ba227b11efc602a6a95ccdccaabf41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('udemy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
