{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgbのためのデータセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Mydataset import MyDataset\n",
    "import os\n",
    "import glob\n",
    "\n",
    "root_dir = \"./data_temp\"\n",
    "\n",
    "train_indices = [] # 学習データのindex\n",
    "val_indices = [] # validationデータのindex\n",
    "\n",
    "mydataset = MyDataset(root_pth=root_dir, test=False)\n",
    "n_samples = len(mydataset) # サンプル(データ)数 -> 31769\n",
    "folder_count = np.load(os.path.join(root_dir, 'audio', 'folder_count.npy')).tolist()\n",
    "\n",
    "total_num = 0\n",
    "for num in folder_count:\n",
    "    # folder_count : [6134, 4534, 4386, 3994, 4342, 5382, 1100, 1001, 923]\n",
    "    fol_indices = list(range(total_num, total_num+num))\n",
    "    fol_indices = random.sample(fol_indices, num)\n",
    "    # train : validation = 80 : 20\n",
    "    train_size = int(num * 0.8)\n",
    "\n",
    "    train_indices += fol_indices[0:train_size]\n",
    "    val_indices += fol_indices[train_size:]\n",
    "\n",
    "    total_num += num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24683\n",
      "6176\n",
      "30859\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indices))\n",
    "print(len(val_indices))\n",
    "print(len(train_indices) + len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files :  30859\n",
      "X_train :  24683    y_train :  24683\n",
      "X_valid :  6176    y_valid :  6176\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "y_train = []\n",
    "y_valid = []\n",
    "\n",
    "filling_type = np.load(\"./data_temp/audio/filling_type.npy\")\n",
    "pouring_or_shaking = np.load(\"./data_temp/audio/pouring_or_shaking.npy\")\n",
    "label = filling_type * pouring_or_shaking\n",
    "\n",
    "files = glob.glob(\"./data_temp/audio/mfcc/*.npy\")\n",
    "print(\"files : \", len(files))\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    if i in train_indices:\n",
    "        X_train.append(np.load(file))\n",
    "        y_train.append(label[i])\n",
    "    if i in val_indices:\n",
    "        X_valid.append(np.load(file))\n",
    "        y_valid.append(label[i])\n",
    "\n",
    "print(\"X_train : \", len(X_train), \"   y_train : \", len(y_train))\n",
    "print(\"X_valid : \", len(X_valid), \"   y_valid : \", len(y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\" : [1,2,3,4,5],\n",
    "    \"min_sample_leaf\" : [1,2,3,4,5,6,7,8,9,10],\n",
    "    \"min_sample_split\" : [2,3,4,5]\n",
    "}\n",
    "\n",
    "# データ型の変換\n",
    "X_train, y_train = np.asarray(X_train), np.asarray(y_train)\n",
    "X_valid, y_valid = np.asarray(X_valid), np.asarray(y_valid)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "forest = GridSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 勘違いしてた。別にxgbostはaudioでOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Mydataset import MyDataset\n",
    "import os\n",
    "import glob\n",
    "import scipy.io.wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116940, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(935520,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate, audio = scipy.io.wavfile.read(\"data_temp/1/audio/s0_fi0_fu0_b0_l0_audio.wav\")\n",
    "print(audio.shape)\n",
    "audio = audio.reshape(-1)\n",
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102387, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(819096,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate, audio1 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l1_audio.wav\")\n",
    "print(audio1.shape)\n",
    "audio1 = audio1.reshape(-1)\n",
    "audio1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116424"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = audio.shape[0]\n",
    "padding_len = max - audio1.shape[0]\n",
    "padding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935520,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(audio1, (0, padding_len), \"constant\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path -> root_pth\n",
    "root_pth = \"./data\"\n",
    "\n",
    "# df <- annotations.csv\n",
    "df = pd.read_csv('annotations_sort.csv', header = 0)\n",
    "df_len=len(df) # データ数\n",
    "\n",
    "# 以下xgboost用の変数\n",
    "audio_filling_type = [] # audio用のlabel\n",
    "audio_pour_shake = []\n",
    "audio_max = 0\n",
    "\n",
    "for fileidx in range(df_len):\n",
    "    # pandas : df.iatの説明\n",
    "    # https://note.nkmk.me/python-pandas-at-iat-loc-iloc/\n",
    "    file_name = df.iat[fileidx, 2]\n",
    "    folder_num = df.iat[fileidx, 0] # container_id\n",
    "    start_time =  df.iat[fileidx, 9] # start\n",
    "    end_time = df.iat[fileidx, 10] # end\n",
    "    filling_type = df.iat[fileidx, 4] # filling_type:0~3(none pasta rice water)\n",
    "    \n",
    "    # python : rsplitの説明\n",
    "    # https://note.nkmk.me/python-split-rsplit-splitlines-re/\n",
    "    # s0_fi0_fu0_b0_l0_c2 -> s0_fi0_fu0_b0_l0_audio.wav\n",
    "    audio_filename = file_name.rsplit(\"_\", 1)[0] + '_audio.wav'\n",
    "\n",
    "    audio_path = os.path.join(root_pth, str(folder_num), 'audio', audio_filename)\n",
    "    # 377番目の音声データは飛ばす\n",
    "    if audio_path == \"./data/1/audio/s2_fi1_fu2_b1_l0_audio.wav\" :\n",
    "        continue\n",
    "\n",
    "    # wavファイルの読み取り : scipy.io.wavfile ↓公式サイト\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html\n",
    "    # 返り値 : sample_rate==int signal==numpy array (N_samples, N_channels)\n",
    "    sample_rate, signal = scipy.io.wavfile.read(audio_path)\n",
    "    # sample_rate:44100, signal:(N, 8)(numpy.ndarray)\n",
    "\n",
    "    # numpyのcast \n",
    "    # https://note.nkmk.me/python-numpy-dtype-astype/\n",
    "    signal = signal.astype(\"float32\")\n",
    "    # トリミング手法\n",
    "    # https://librosa.org/doc/main/generated/librosa.effects.trim.html\n",
    "    signal /= np.abs(signal).max() # 正規化\n",
    "\n",
    "    # xgboost 用のデータ処理\n",
    "    audio_filling_type.append(filling_type)\n",
    "    # container_id(folder_num)が1~6ならpouring, 7~9:shaking\n",
    "    pouring = [1,2,3,4,5,6]\n",
    "    shaking = [7,8,9]\n",
    "    if folder_num in pouring :\n",
    "        audio_pour_shake.append(1)\n",
    "    elif folder_num in shaking:\n",
    "        audio_pour_shake.append(0)\n",
    "    else :\n",
    "        print(\"no container id\")\n",
    "    \n",
    "    # 次元を揃えるために一番次元の長いやつを求めておく\n",
    "    if audio_max < signal.reshape(-1).shape[0]:\n",
    "        audio_max = signal.reshape(-1).shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "sample_rate, audio1 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l0_audio.wav\")\n",
    "sample_rate, audio2 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l1_audio.wav\")\n",
    "\n",
    "X_train = []\n",
    "X_train.append(audio1)\n",
    "X_train.append(audio2)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116940,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio1.reshape(-1).shape[0]\n",
    "audio1.shape\n",
    "audio1[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling_type :  683\n",
      "pour_or_shake :  683\n",
      "label :  683\n",
      "label-kind :  [0 1 2 3]\n",
      "max_length :  1587410\n",
      "audio_x :  683\n",
      "audio_y :  683\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "audio_y==0 :  252\n",
      "audio_y==1 :  143\n",
      "audio_y==2 :  144\n",
      "audio_y==3 :  144\n",
      "683\n"
     ]
    }
   ],
   "source": [
    "audio_x = []\n",
    "audio_y = []\n",
    "\n",
    "filling_type = np.load(\"./data/audio/audio_filling_type.npy\")\n",
    "pour_or_shake = np.load(\"./data/audio/audio_pour_shake.npy\")\n",
    "label = filling_type * pour_or_shake\n",
    "\n",
    "print(\"filling_type : \", len(filling_type))\n",
    "print(\"pour_or_shake : \", len(pour_or_shake))\n",
    "print(\"label : \", len(label))\n",
    "print(\"label-kind : \", np.unique(np.array(label)))\n",
    "\n",
    "# チャンネル1だけでやってみる\n",
    "total_idx = 0\n",
    "max_length = 0\n",
    "for i in range(1, 10):\n",
    "    files = glob.glob(f\"./data/{i}/audio/*.wav\")\n",
    "    for idx, file in enumerate(files):\n",
    "        sample_rate, audio = scipy.io.wavfile.read(file)\n",
    "        if max_length < audio[:,0].shape[0]:\n",
    "            max_length = audio[:,0].shape[0]\n",
    "        # print(type(audio))\n",
    "        # break\n",
    "        # audio_x.append(audio)\n",
    "        # audio_y.append(label[total_idx + idx])\n",
    "\n",
    "print('max_length : ', max_length)\n",
    "total_idx = 0       \n",
    "for i in range(1, 10):\n",
    "    files = glob.glob(f\"./data/{i}/audio/*.wav\")\n",
    "    # print('files ; ', len(files))\n",
    "    count = 0\n",
    "    for idx, file in enumerate(files):\n",
    "        sample_rate, audio = scipy.io.wavfile.read(file)\n",
    "        pad_len = max_length - audio[:,0].shape[0]\n",
    "        audio_x.append(np.pad(audio[:,0], (0, pad_len), \"constant\"))\n",
    "        audio_y.append(label[total_idx+idx])\n",
    "        count += 1\n",
    "    total_idx += count\n",
    "\n",
    "print(\"audio_x : \", len(audio_x))\n",
    "print(\"audio_y : \", len(audio_y))\n",
    "\n",
    "filling_type = np.array(filling_type)\n",
    "print(np.unique(filling_type))\n",
    "audio_x = np.array(audio_x)\n",
    "audio_y = np.array(audio_y)\n",
    "print(np.unique(audio_y))\n",
    "print(\"audio_y==0 : \", np.count_nonzero(audio_y==0))\n",
    "print(\"audio_y==1 : \", np.count_nonzero(audio_y==1))\n",
    "print(\"audio_y==2 : \", np.count_nonzero(audio_y==2))\n",
    "print(\"audio_y==3 : \", np.count_nonzero(audio_y==3))\n",
    "print(252 + 143 + 144 + 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 1587410)\n",
      "(1587410,)\n"
     ]
    }
   ],
   "source": [
    "print(audio_x.shape)\n",
    "print(audio_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/initial/.pyenv/versions/3.8.10/envs/corsmal/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"min_child_weigh\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:54:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(audio_x, audio_y,\n",
    "                                                      test_size=0.2,\n",
    "                                                      shuffle=True,\n",
    "                                                      random_state=0)\n",
    "\n",
    "params = {\n",
    "    \"eta\" : [0.01, 1.0, 1.0],\n",
    "    \"gamma\" : [0, 0.1],\n",
    "    \"n_estimators\" : [10, 100],\n",
    "    \"max_depth\" : [2,3,4],\n",
    "    \"min_child_weight\" : [1,2]\n",
    "}\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "forest = GridSearchCV(model ,params, cv=skf, scoring=\"accuracy\", n_jobs=1, verbose=3)\n",
    "forest.fit(X_train, y_train)\n",
    "best_params = forest.best_params_\n",
    "print(best_params)\n",
    "best_score = forest.best_score_\n",
    "print(\"best score : \", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f5b1a9f36cac5504d3212872bcc323699452b76dcccf68776354c7e475628a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
