{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgbのためのデータセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Mydataset import MyDataset\n",
    "import os\n",
    "import glob\n",
    "\n",
    "root_dir = \"./data_temp\"\n",
    "\n",
    "train_indices = [] # 学習データのindex\n",
    "val_indices = [] # validationデータのindex\n",
    "\n",
    "mydataset = MyDataset(root_pth=root_dir, test=False)\n",
    "n_samples = len(mydataset) # サンプル(データ)数 -> 31769\n",
    "folder_count = np.load(os.path.join(root_dir, 'audio', 'folder_count.npy')).tolist()\n",
    "\n",
    "total_num = 0\n",
    "for num in folder_count:\n",
    "    # folder_count : [6134, 4534, 4386, 3994, 4342, 5382, 1100, 1001, 923]\n",
    "    fol_indices = list(range(total_num, total_num+num))\n",
    "    fol_indices = random.sample(fol_indices, num)\n",
    "    # train : validation = 80 : 20\n",
    "    train_size = int(num * 0.8)\n",
    "\n",
    "    train_indices += fol_indices[0:train_size]\n",
    "    val_indices += fol_indices[train_size:]\n",
    "\n",
    "    total_num += num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24683\n",
      "6176\n",
      "30859\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indices))\n",
    "print(len(val_indices))\n",
    "print(len(train_indices) + len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files :  30859\n",
      "X_train :  24683    y_train :  24683\n",
      "X_valid :  6176    y_valid :  6176\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "y_train = []\n",
    "y_valid = []\n",
    "\n",
    "filling_type = np.load(\"./data_temp/audio/filling_type.npy\")\n",
    "pouring_or_shaking = np.load(\"./data_temp/audio/pouring_or_shaking.npy\")\n",
    "label = filling_type * pouring_or_shaking\n",
    "\n",
    "files = glob.glob(\"./data_temp/audio/mfcc/*.npy\")\n",
    "print(\"files : \", len(files))\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    if i in train_indices:\n",
    "        X_train.append(np.load(file))\n",
    "        y_train.append(label[i])\n",
    "    if i in val_indices:\n",
    "        X_valid.append(np.load(file))\n",
    "        y_valid.append(label[i])\n",
    "\n",
    "print(\"X_train : \", len(X_train), \"   y_train : \", len(y_train))\n",
    "print(\"X_valid : \", len(X_valid), \"   y_valid : \", len(y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\" : [1,2,3,4,5],\n",
    "    \"min_sample_leaf\" : [1,2,3,4,5,6,7,8,9,10],\n",
    "    \"min_sample_split\" : [2,3,4,5]\n",
    "}\n",
    "\n",
    "# データ型の変換\n",
    "X_train, y_train = np.asarray(X_train), np.asarray(y_train)\n",
    "X_valid, y_valid = np.asarray(X_valid), np.asarray(y_valid)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "forest = GridSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 勘違いしてた。別にxgbostはaudioでOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Mydataset import MyDataset\n",
    "import os\n",
    "import glob\n",
    "import scipy.io.wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116940, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(935520,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate, audio = scipy.io.wavfile.read(\"data_temp/1/audio/s0_fi0_fu0_b0_l0_audio.wav\")\n",
    "print(audio.shape)\n",
    "audio = audio.reshape(-1)\n",
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102387, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(819096,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate, audio1 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l1_audio.wav\")\n",
    "print(audio1.shape)\n",
    "audio1 = audio1.reshape(-1)\n",
    "audio1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116424"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = audio.shape[0]\n",
    "padding_len = max - audio1.shape[0]\n",
    "padding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935520,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(audio1, (0, padding_len), \"constant\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path -> root_pth\n",
    "root_pth = \"./data\"\n",
    "\n",
    "# df <- annotations.csv\n",
    "df = pd.read_csv('annotations_sort.csv', header = 0)\n",
    "df_len=len(df) # データ数\n",
    "\n",
    "# 以下xgboost用の変数\n",
    "audio_filling_type = [] # audio用のlabel\n",
    "audio_pour_shake = []\n",
    "audio_max = 0\n",
    "\n",
    "for fileidx in range(df_len):\n",
    "    # pandas : df.iatの説明\n",
    "    # https://note.nkmk.me/python-pandas-at-iat-loc-iloc/\n",
    "    file_name = df.iat[fileidx, 2]\n",
    "    folder_num = df.iat[fileidx, 0] # container_id\n",
    "    start_time =  df.iat[fileidx, 9] # start\n",
    "    end_time = df.iat[fileidx, 10] # end\n",
    "    filling_type = df.iat[fileidx, 4] # filling_type:0~3(none pasta rice water)\n",
    "    \n",
    "    # python : rsplitの説明\n",
    "    # https://note.nkmk.me/python-split-rsplit-splitlines-re/\n",
    "    # s0_fi0_fu0_b0_l0_c2 -> s0_fi0_fu0_b0_l0_audio.wav\n",
    "    audio_filename = file_name.rsplit(\"_\", 1)[0] + '_audio.wav'\n",
    "\n",
    "    audio_path = os.path.join(root_pth, str(folder_num), 'audio', audio_filename)\n",
    "    # 377番目の音声データは飛ばす\n",
    "    if audio_path == \"./data/1/audio/s2_fi1_fu2_b1_l0_audio.wav\" :\n",
    "        continue\n",
    "\n",
    "    # wavファイルの読み取り : scipy.io.wavfile ↓公式サイト\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html\n",
    "    # 返り値 : sample_rate==int signal==numpy array (N_samples, N_channels)\n",
    "    sample_rate, signal = scipy.io.wavfile.read(audio_path)\n",
    "    # sample_rate:44100, signal:(N, 8)(numpy.ndarray)\n",
    "\n",
    "    # numpyのcast \n",
    "    # https://note.nkmk.me/python-numpy-dtype-astype/\n",
    "    signal = signal.astype(\"float32\")\n",
    "    # トリミング手法\n",
    "    # https://librosa.org/doc/main/generated/librosa.effects.trim.html\n",
    "    signal /= np.abs(signal).max() # 正規化\n",
    "\n",
    "    # xgboost 用のデータ処理\n",
    "    audio_filling_type.append(filling_type)\n",
    "    # container_id(folder_num)が1~6ならpouring, 7~9:shaking\n",
    "    pouring = [1,2,3,4,5,6]\n",
    "    shaking = [7,8,9]\n",
    "    if folder_num in pouring :\n",
    "        audio_pour_shake.append(1)\n",
    "    elif folder_num in shaking:\n",
    "        audio_pour_shake.append(0)\n",
    "    else :\n",
    "        print(\"no container id\")\n",
    "    \n",
    "    # 次元を揃えるために一番次元の長いやつを求めておく\n",
    "    if audio_max < signal.reshape(-1).shape[0]:\n",
    "        audio_max = signal.reshape(-1).shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "sample_rate, audio1 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l0_audio.wav\")\n",
    "sample_rate, audio2 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l1_audio.wav\")\n",
    "\n",
    "X_train = []\n",
    "X_train.append(audio1)\n",
    "X_train.append(audio2)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116940,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio1.reshape(-1).shape[0]\n",
    "audio1.shape\n",
    "audio1[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling_type :  683\n",
      "pour_or_shake :  683\n",
      "label :  683\n",
      "label-kind :  [0 1 2 3]\n",
      "max_length :  1587410\n",
      "audio_x :  683\n",
      "audio_y :  683\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "audio_y==0 :  252\n",
      "audio_y==1 :  143\n",
      "audio_y==2 :  144\n",
      "audio_y==3 :  144\n",
      "683\n"
     ]
    }
   ],
   "source": [
    "audio_x = []\n",
    "audio_y = []\n",
    "\n",
    "filling_type = np.load(\"./data/audio/audio_filling_type.npy\")\n",
    "pour_or_shake = np.load(\"./data/audio/audio_pour_shake.npy\")\n",
    "label = filling_type * pour_or_shake\n",
    "\n",
    "print(\"filling_type : \", len(filling_type))\n",
    "print(\"pour_or_shake : \", len(pour_or_shake))\n",
    "print(\"label : \", len(label))\n",
    "print(\"label-kind : \", np.unique(np.array(label)))\n",
    "\n",
    "# チャンネル1だけでやってみる\n",
    "total_idx = 0\n",
    "max_length = 0\n",
    "for i in range(1, 10):\n",
    "    files = glob.glob(f\"./data/{i}/audio/*.wav\")\n",
    "    for idx, file in enumerate(files):\n",
    "        sample_rate, audio = scipy.io.wavfile.read(file)\n",
    "        if max_length < audio[:,0].shape[0]:\n",
    "            max_length = audio[:,0].shape[0]\n",
    "        # print(type(audio))\n",
    "        # break\n",
    "        # audio_x.append(audio)\n",
    "        # audio_y.append(label[total_idx + idx])\n",
    "\n",
    "print('max_length : ', max_length)\n",
    "total_idx = 0       \n",
    "for i in range(1, 10):\n",
    "    files = glob.glob(f\"./data/{i}/audio/*.wav\")\n",
    "    # print('files ; ', len(files))\n",
    "    count = 0\n",
    "    for idx, file in enumerate(files):\n",
    "        sample_rate, audio = scipy.io.wavfile.read(file)\n",
    "        pad_len = max_length - audio[:,0].shape[0]\n",
    "        audio_x.append(np.pad(audio[:,0], (0, pad_len), \"constant\"))\n",
    "        audio_y.append(label[total_idx+idx])\n",
    "        count += 1\n",
    "    total_idx += count\n",
    "\n",
    "print(\"audio_x : \", len(audio_x))\n",
    "print(\"audio_y : \", len(audio_y))\n",
    "\n",
    "filling_type = np.array(filling_type)\n",
    "print(np.unique(filling_type))\n",
    "audio_x = np.array(audio_x)\n",
    "audio_y = np.array(audio_y)\n",
    "print(np.unique(audio_y))\n",
    "print(\"audio_y==0 : \", np.count_nonzero(audio_y==0))\n",
    "print(\"audio_y==1 : \", np.count_nonzero(audio_y==1))\n",
    "print(\"audio_y==2 : \", np.count_nonzero(audio_y==2))\n",
    "print(\"audio_y==3 : \", np.count_nonzero(audio_y==3))\n",
    "print(252 + 143 + 144 + 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 1587410)\n",
      "(1587410,)\n"
     ]
    }
   ],
   "source": [
    "print(audio_x.shape)\n",
    "print(audio_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.01945\teval-mlogloss:1.34267\n",
      "[1]\ttrain-mlogloss:0.77658\teval-mlogloss:1.33808\n",
      "[2]\ttrain-mlogloss:0.59060\teval-mlogloss:1.34531\n",
      "[3]\ttrain-mlogloss:0.44595\teval-mlogloss:1.33524\n",
      "[4]\ttrain-mlogloss:0.34250\teval-mlogloss:1.34560\n",
      "[5]\ttrain-mlogloss:0.27169\teval-mlogloss:1.34890\n",
      "[6]\ttrain-mlogloss:0.21600\teval-mlogloss:1.35028\n",
      "[7]\ttrain-mlogloss:0.17119\teval-mlogloss:1.35117\n",
      "[8]\ttrain-mlogloss:0.13845\teval-mlogloss:1.35061\n",
      "[9]\ttrain-mlogloss:0.11447\teval-mlogloss:1.33090\n",
      "[10]\ttrain-mlogloss:0.09425\teval-mlogloss:1.32172\n",
      "[11]\ttrain-mlogloss:0.07820\teval-mlogloss:1.32419\n",
      "[12]\ttrain-mlogloss:0.06617\teval-mlogloss:1.32934\n",
      "[13]\ttrain-mlogloss:0.05670\teval-mlogloss:1.32047\n",
      "[14]\ttrain-mlogloss:0.04898\teval-mlogloss:1.32559\n",
      "[15]\ttrain-mlogloss:0.04286\teval-mlogloss:1.31748\n",
      "[16]\ttrain-mlogloss:0.03798\teval-mlogloss:1.32680\n",
      "[17]\ttrain-mlogloss:0.03377\teval-mlogloss:1.31745\n",
      "[18]\ttrain-mlogloss:0.03045\teval-mlogloss:1.32019\n",
      "[19]\ttrain-mlogloss:0.02767\teval-mlogloss:1.32303\n",
      "[20]\ttrain-mlogloss:0.02530\teval-mlogloss:1.33499\n",
      "[21]\ttrain-mlogloss:0.02323\teval-mlogloss:1.34017\n",
      "[22]\ttrain-mlogloss:0.02144\teval-mlogloss:1.33945\n",
      "[23]\ttrain-mlogloss:0.02002\teval-mlogloss:1.34566\n",
      "[24]\ttrain-mlogloss:0.01869\teval-mlogloss:1.34533\n",
      "[25]\ttrain-mlogloss:0.01756\teval-mlogloss:1.34840\n",
      "[26]\ttrain-mlogloss:0.01655\teval-mlogloss:1.35474\n",
      "[27]\ttrain-mlogloss:0.01568\teval-mlogloss:1.35317\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2671/3181637366.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mva_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mscore_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mscore_logloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/envs/corsmal/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/envs/corsmal/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(audio_x, audio_y,\n",
    "                                                      test_size=0.2,\n",
    "                                                      shuffle=True,\n",
    "                                                      random_state=0)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "watchlist = [(dtrain, \"train\"), (dvalid, \"eval\")]\n",
    "# main parameter\n",
    "params = {\n",
    "    \"objective\" : 'multi:softprob',\n",
    "    \"num_class\" : 4,\n",
    "    \"eval_metric\" : \"mlogloss\"\n",
    "}\n",
    "num_round = 50\n",
    "\n",
    "# params_space = {\n",
    "#     \"eta\" : [0.01, 1.0, 1.0],\n",
    "#     \"gamma\" : [0, 0.1],\n",
    "#     \"n_estimators\" : [10, 100],\n",
    "#     \"max_depth\" : [2,3,4],\n",
    "#     \"min_child_weight\" : [1,2]um\n",
    "# }\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# forest = GridSearchCV(model ,params_space, cv=skf, scoring=\"accuracy\", n_jobs=1, verbose=3)\n",
    "# forest.fit(X_train, y_train)\n",
    "# best_params = forest.best_params_\n",
    "# print(best_params)\n",
    "# best_score = forest.best_score_\n",
    "# print(\"best score : \", best_score)\n",
    "\n",
    "va_pred = model.predict(dvalid)\n",
    "va_pred = np.argmax(va_pred, axis=1)\n",
    "score_acc = accuracy_score(y_valid, va_pred)\n",
    "score_logloss = log_loss(y_valid, va_pred)\n",
    "print(\"acc : \", score_acc)\n",
    "print(\"log-loss : \", score_logloss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(va_pred, axis=1)\n",
    "y_valid.shape\n",
    "va_pred.shape\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(pred))\n",
    "print(np.unique(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 3, 3, 2, 3, 0, 0, 1, 2, 3, 0, 2, 1, 2, 3, 3, 2, 1, 0,\n",
       "       3, 0, 2, 2, 0, 0, 3, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 1, 3, 0, 0,\n",
       "       3, 0, 2, 1, 2, 0, 0, 2, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0,\n",
       "       3, 0, 0, 3, 0, 0, 0, 1, 0, 1, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0,\n",
       "       2, 3, 3, 0, 3, 3, 0, 1, 2, 2, 2, 1, 0, 2, 1, 3, 0, 1, 1, 2, 1, 0,\n",
       "       0, 1, 2, 1, 3, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 2, 0, 1, 3, 0, 0, 0,\n",
       "       0, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 0, 3, 2, 3, 2, 3, 0, 2, 2, 2, 0, 0, 1, 1, 3, 3, 2, 3, 3,\n",
       "       0, 0, 1, 1, 0, 1, 3, 0, 0, 0, 1, 3, 0, 3, 0, 2, 1, 1, 3, 2, 2, 0,\n",
       "       2, 0, 2, 3, 0, 0, 1, 0, 3, 0, 2, 0, 3, 0, 2, 0, 3, 1, 2, 0, 2, 3,\n",
       "       3, 3, 1, 3, 0, 0, 2, 2, 3, 1, 3, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 2, 1, 1, 3, 3, 0, 0, 2, 3, 0, 0, 2, 1, 1, 2, 1, 1, 3, 1, 0,\n",
       "       0, 0, 3, 2, 1, 0, 0, 3, 1, 1, 2, 2, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0,\n",
       "       3, 1, 0, 3, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc :  0.43795620437956206\n"
     ]
    }
   ],
   "source": [
    "score_acc = accuracy_score(y_valid, pred)\n",
    "# score_logloss = log_loss(y_valid, pred)\n",
    "print(\"acc : \", score_acc)\n",
    "# print(\"log-loss : \", score_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f5b1a9f36cac5504d3212872bcc323699452b76dcccf68776354c7e475628a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
