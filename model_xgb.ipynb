{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgbのためのデータセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Mydataset import MyDataset\n",
    "import os\n",
    "import glob\n",
    "\n",
    "root_dir = \"./data_temp\"\n",
    "\n",
    "train_indices = [] # 学習データのindex\n",
    "val_indices = [] # validationデータのindex\n",
    "\n",
    "mydataset = MyDataset(root_pth=root_dir, test=False)\n",
    "n_samples = len(mydataset) # サンプル(データ)数 -> 31769\n",
    "folder_count = np.load(os.path.join(root_dir, 'audio', 'folder_count.npy')).tolist()\n",
    "\n",
    "total_num = 0\n",
    "for num in folder_count:\n",
    "    # folder_count : [6134, 4534, 4386, 3994, 4342, 5382, 1100, 1001, 923]\n",
    "    fol_indices = list(range(total_num, total_num+num))\n",
    "    fol_indices = random.sample(fol_indices, num)\n",
    "    # train : validation = 80 : 20\n",
    "    train_size = int(num * 0.8)\n",
    "\n",
    "    train_indices += fol_indices[0:train_size]\n",
    "    val_indices += fol_indices[train_size:]\n",
    "\n",
    "    total_num += num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_indices))\n",
    "print(len(val_indices))\n",
    "print(len(train_indices) + len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "y_train = []\n",
    "y_valid = []\n",
    "\n",
    "filling_type = np.load(\"./data_temp/audio/filling_type.npy\")\n",
    "pouring_or_shaking = np.load(\"./data_temp/audio/pouring_or_shaking.npy\")\n",
    "label = filling_type * pouring_or_shaking\n",
    "\n",
    "files = glob.glob(\"./data_temp/audio/mfcc/*.npy\")\n",
    "print(\"files : \", len(files))\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    if i in train_indices:\n",
    "        X_train.append(np.load(file))\n",
    "        y_train.append(label[i])\n",
    "    if i in val_indices:\n",
    "        X_valid.append(np.load(file))\n",
    "        y_valid.append(label[i])\n",
    "\n",
    "print(\"X_train : \", len(X_train), \"   y_train : \", len(y_train))\n",
    "print(\"X_valid : \", len(X_valid), \"   y_valid : \", len(y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"max_depth\" : [1,2,3,4,5],\n",
    "    \"min_sample_leaf\" : [1,2,3,4,5,6,7,8,9,10],\n",
    "    \"min_sample_split\" : [2,3,4,5]\n",
    "}\n",
    "\n",
    "# データ型の変換\n",
    "X_train, y_train = np.asarray(X_train), np.asarray(y_train)\n",
    "X_valid, y_valid = np.asarray(X_valid), np.asarray(y_valid)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "forest = GridSearchCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 勘違いしてた。別にxgbostはaudioでOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Mydataset import MyDataset\n",
    "import os\n",
    "import glob\n",
    "import scipy.io.wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, audio = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l0_audio.wav\")\n",
    "print(audio.shape)\n",
    "audio = audio.reshape(-1)\n",
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, audio1 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l1_audio.wav\")\n",
    "print(audio1.shape)\n",
    "audio1 = audio1.reshape(-1)\n",
    "audio1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = audio.shape[0]\n",
    "padding_len = max - audio1.shape[0]\n",
    "padding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pad(audio1, (0, padding_len), \"constant\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path -> root_pth\n",
    "root_pth = \"./data\"\n",
    "\n",
    "# df <- annotations.csv\n",
    "df = pd.read_csv('annotations_sort.csv', header = 0)\n",
    "df_len=len(df) # データ数\n",
    "\n",
    "# 以下xgboost用の変数\n",
    "audio_filling_type = [] # audio用のlabel\n",
    "audio_pour_shake = []\n",
    "audio_max = 0\n",
    "\n",
    "for fileidx in range(df_len):\n",
    "    # pandas : df.iatの説明\n",
    "    # https://note.nkmk.me/python-pandas-at-iat-loc-iloc/\n",
    "    file_name = df.iat[fileidx, 2]\n",
    "    folder_num = df.iat[fileidx, 0] # container_id\n",
    "    start_time =  df.iat[fileidx, 9] # start\n",
    "    end_time = df.iat[fileidx, 10] # end\n",
    "    filling_type = df.iat[fileidx, 4] # filling_type:0~3(none pasta rice water)\n",
    "    \n",
    "    # python : rsplitの説明\n",
    "    # https://note.nkmk.me/python-split-rsplit-splitlines-re/\n",
    "    # s0_fi0_fu0_b0_l0_c2 -> s0_fi0_fu0_b0_l0_audio.wav\n",
    "    audio_filename = file_name.rsplit(\"_\", 1)[0] + '_audio.wav'\n",
    "\n",
    "    audio_path = os.path.join(root_pth, str(folder_num), 'audio', audio_filename)\n",
    "    # 377番目の音声データは飛ばす\n",
    "    if audio_path == \"./data/1/audio/s2_fi1_fu2_b1_l0_audio.wav\" :\n",
    "        continue\n",
    "\n",
    "    # wavファイルの読み取り : scipy.io.wavfile ↓公式サイト\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html\n",
    "    # 返り値 : sample_rate==int signal==numpy array (N_samples, N_channels)\n",
    "    sample_rate, signal = scipy.io.wavfile.read(audio_path)\n",
    "    # sample_rate:44100, signal:(N, 8)(numpy.ndarray)\n",
    "\n",
    "    # numpyのcast \n",
    "    # https://note.nkmk.me/python-numpy-dtype-astype/\n",
    "    signal = signal.astype(\"float32\")\n",
    "    # トリミング手法\n",
    "    # https://librosa.org/doc/main/generated/librosa.effects.trim.html\n",
    "    signal /= np.abs(signal).max() # 正規化\n",
    "\n",
    "    # xgboost 用のデータ処理\n",
    "    audio_filling_type.append(filling_type)\n",
    "    # container_id(folder_num)が1~6ならpouring, 7~9:shaking\n",
    "    pouring = [1,2,3,4,5,6]\n",
    "    shaking = [7,8,9]\n",
    "    if folder_num in pouring :\n",
    "        audio_pour_shake.append(1)\n",
    "    elif folder_num in shaking:\n",
    "        audio_pour_shake.append(0)\n",
    "    else :\n",
    "        print(\"no container id\")\n",
    "    \n",
    "    # 次元を揃えるために一番次元の長いやつを求めておく\n",
    "    if audio_max < signal.reshape(-1).shape[0]:\n",
    "        audio_max = signal.reshape(-1).shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, audio1 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l0_audio.wav\")\n",
    "sample_rate, audio2 = scipy.io.wavfile.read(\"data/1/audio/s0_fi0_fu0_b0_l1_audio.wav\")\n",
    "\n",
    "X_train = []\n",
    "X_train.append(audio1)\n",
    "X_train.append(audio2)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1.reshape(-1).shape[0]\n",
    "audio1.shape\n",
    "audio1[:, 0].shape\n",
    "audio1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(audio2.shape[1]):\n",
    "    print(f\"audio1[:, {i}] : \", audio2[:, i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_x = []\n",
    "audio_y = []\n",
    "\n",
    "filling_type = np.load(\"./data/audio/audio_filling_type.npy\")\n",
    "pour_or_shake = np.load(\"./data/audio/audio_pour_shake.npy\")\n",
    "label = filling_type * pour_or_shake\n",
    "\n",
    "print(\"filling_type : \", len(filling_type))\n",
    "print(\"pour_or_shake : \", len(pour_or_shake))\n",
    "print(\"label : \", len(label))\n",
    "print(\"label-kind : \", np.unique(np.array(label)))\n",
    "\n",
    "# チャンネル1だけでやってみる\n",
    "total_idx = 0\n",
    "max_length = 0\n",
    "for i in range(1, 10):\n",
    "    files = glob.glob(f\"./data/{i}/audio/*.wav\")\n",
    "    for idx, file in enumerate(files):\n",
    "        sample_rate, audio = scipy.io.wavfile.read(file)\n",
    "        if max_length < audio[:,0].shape[0]:\n",
    "            max_length = audio[:,0].shape[0]\n",
    "        # print(type(audio))\n",
    "        # break\n",
    "        # audio_x.append(audio)\n",
    "        # audio_y.append(label[total_idx + idx])\n",
    "\n",
    "print('max_length : ', max_length)\n",
    "total_idx = 0       \n",
    "for i in range(1, 10):\n",
    "    files = glob.glob(f\"./data/{i}/audio/*.wav\")\n",
    "    count = 0\n",
    "    for idx, file in enumerate(files):\n",
    "        audio_temp = []\n",
    "        sample_rate, audio = scipy.io.wavfile.read(file)\n",
    "        pad_len = max_length - audio[:,0].shape[0]\n",
    "        for j in range(audio.shape[1]):\n",
    "            # audio_temp.append(np.pad(audio[:,j], (0, pad_len), \"constant\"))\n",
    "            audio_x.append(np.pad(audio[:,j], (0, pad_len), \"constant\"))\n",
    "            audio_y.append(label[total_idx+idx])\n",
    "        # print(\"audio_length : \", len(audio_temp))\n",
    "        # print(\"audio_concat : \", np.asarray(audio_temp).shape)\n",
    "        # print(\"transpose  :\", np.vstack(audio_temp).transpose(1, 0).shape)\n",
    "        # audio_x.append(np.vstack(audio_temp).transpose(1,0))\n",
    "        # audio_y.append(label[total_idx+idx])\n",
    "        count += 1\n",
    "    total_idx += count\n",
    "\n",
    "print(\"audio_x : \", len(audio_x))\n",
    "print(\"audio_y : \", len(audio_y))\n",
    "\n",
    "filling_type = np.array(filling_type)\n",
    "print(np.unique(filling_type))\n",
    "audio_x = np.array(audio_x)\n",
    "audio_y = np.array(audio_y)\n",
    "print(np.unique(audio_y))\n",
    "print(\"audio_y==0 : \", np.count_nonzero(audio_y==0))\n",
    "print(\"audio_y==1 : \", np.count_nonzero(audio_y==1))\n",
    "print(\"audio_y==2 : \", np.count_nonzero(audio_y==2))\n",
    "print(\"audio_y==3 : \", np.count_nonzero(audio_y==3))\n",
    "print(252 + 143 + 144 + 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio_x.shape)\n",
    "print(audio_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(audio_x, audio_y,\n",
    "                                                      test_size=0.2,\n",
    "                                                      shuffle=True,\n",
    "                                                      random_state=0)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "watchlist = [(dtrain, \"train\"), (dvalid, \"eval\")]\n",
    "# main parameter\n",
    "params = {\n",
    "    \"objective\" : 'multi:softprob',\n",
    "    \"num_class\" : 4,\n",
    "    \"eval_metric\" : \"mlogloss\"\n",
    "}\n",
    "num_round = 50\n",
    "\n",
    "# params_space = {\n",
    "#     \"eta\" : [0.01, 1.0, 1.0],\n",
    "#     \"gamma\" : [0, 0.1],\n",
    "#     \"n_estimators\" : [10, 100],\n",
    "#     \"max_depth\" : [2,3,4],\n",
    "#     \"min_child_weight\" : [1,2]um\n",
    "# }\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# forest = GridSearchCV(model ,params_space, cv=skf, scoring=\"accuracy\", n_jobs=1, verbose=3)\n",
    "# forest.fit(X_train, y_train)\n",
    "# best_params = forest.best_params_\n",
    "# print(best_params)\n",
    "# best_score = forest.best_score_\n",
    "# print(\"best score : \", best_score)\n",
    "\n",
    "va_pred = model.predict(dvalid)\n",
    "va_pred = np.argmax(va_pred, axis=1)\n",
    "score_acc = accuracy_score(y_valid, va_pred)\n",
    "score_logloss = log_loss(y_valid, va_pred)\n",
    "print(\"acc : \", score_acc)\n",
    "print(\"log-loss : \", score_logloss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(va_pred, axis=1)\n",
    "y_valid.shape\n",
    "va_pred.shape\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(pred))\n",
    "print(np.unique(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_acc = accuracy_score(y_valid, pred)\n",
    "# score_logloss = log_loss(y_valid, pred)\n",
    "print(\"acc : \", score_acc)\n",
    "# print(\"log-loss : \", score_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "a1 = np.array([1,1,1])\n",
    "a2 = np.array([2,2,2])\n",
    "print(\"a1 : \", a1.shape)\n",
    "print(\"a2 : \", a2.shape)\n",
    "b = []\n",
    "b.append(a1)\n",
    "b.append(a2)\n",
    "print(\"b : \", np.vstack(b).shape)\n",
    "print(\"b : \", np.vstack(b).transpose(1, 0).shape)\n",
    "# print(np.concatenate([a1, a2], 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"./annotations_sort.csv\")\n",
    "print(temp.shape)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = temp.values\n",
    "print(num.shape)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f5b1a9f36cac5504d3212872bcc323699452b76dcccf68776354c7e475628a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
